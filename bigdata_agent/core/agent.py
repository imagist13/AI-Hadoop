"""
å¤§æ•°æ®å¤„ç†Agentæ ¸å¿ƒç±»
é›†æˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›ç»Ÿä¸€çš„æŸ¥è¯¢å¤„ç†æ¥å£
"""

import time
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime

from ..nlp.query_analyzer import QueryAnalyzer
from ..task.task_builder import TaskBuilder
from ..execution.engine_factory import EngineFactory
from ..result.result_processor import ResultProcessor


class BigDataAgent:
    """å¤§æ•°æ®å¤„ç†æ™ºèƒ½ä»£ç†"""

    def __init__(self, engine_type: str = "spark", engine_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–å¤§æ•°æ®Agent

        Args:
            engine_type: æ‰§è¡Œå¼•æ“ç±»å‹ (spark, hive, clickhouse, presto)
            engine_config: å¼•æ“é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.engine_type = engine_type
        self.engine_config = engine_config or EngineFactory.get_engine_config_template(engine_type)

        # åˆå§‹åŒ–ç»„ä»¶
        self.query_analyzer = QueryAnalyzer()
        self.task_builder = TaskBuilder()
        self.result_processor = ResultProcessor()
        self.execution_engine = None

        # è¿æ¥çŠ¶æ€
        self.connected = False

        self.logger = logging.getLogger(__name__)
        self.business_logger = logging.getLogger("business")

        # ç¡®ä¿business loggeræœ‰å¤„ç†å™¨
        if not self.business_logger.handlers:
            from config.logging_config import setup_logging
            # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®æ—¥å¿—ï¼Œå…ˆè®¾ç½®ä¸€ä¸‹
            if not logging.getLogger().handlers:
                setup_logging()

        print("ğŸ¤– BigData Agentåˆå§‹åŒ–å®Œæˆ")
        print(f"   æ‰§è¡Œå¼•æ“: {engine_type}")

        self.logger.info(f"BigData Agentåˆå§‹åŒ–å®Œæˆï¼Œæ‰§è¡Œå¼•æ“: {engine_type}")

    def connect(self) -> bool:
        """
        è¿æ¥åˆ°æ‰§è¡Œå¼•æ“

        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            self.execution_engine = EngineFactory.create_engine(self.engine_type, self.engine_config)
            self.connected = self.execution_engine.connect()

            if self.connected:
                print("âœ… æ‰§è¡Œå¼•æ“è¿æ¥æˆåŠŸ")
            else:
                print("âŒ æ‰§è¡Œå¼•æ“è¿æ¥å¤±è´¥")
            return self.connected

        except Exception as e:
            print(f"âŒ è¿æ¥æ‰§è¡Œå¼•æ“å¤±è´¥: {e}")
            self.connected = False
            return False

    def disconnect(self):
        """æ–­å¼€æ‰§è¡Œå¼•æ“è¿æ¥"""
        if self.execution_engine:
            self.execution_engine.disconnect()
            self.execution_engine = None
        self.connected = False
        print("âœ… æ‰§è¡Œå¼•æ“å·²æ–­å¼€è¿æ¥")

    def query(self, user_query: str, output_format: str = "json", **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œç”¨æˆ·æŸ¥è¯¢

        Args:
            user_query: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            output_format: è¾“å‡ºæ ¼å¼ (json, csv, chart, table)
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            dict: æŸ¥è¯¢ç»“æœ
        """
        if not self.connected:
            return {
                'success': False,
                'error': 'æ‰§è¡Œå¼•æ“æœªè¿æ¥ï¼Œè¯·å…ˆè°ƒç”¨ connect()',
                'timestamp': datetime.now().isoformat()
            }

        start_time = time.time()

        try:
            # è®°å½•ç”¨æˆ·æŸ¥è¯¢
            self.business_logger.info(f"ç”¨æˆ·æŸ¥è¯¢: '{user_query}'")

            # 1. NLPåˆ†ææŸ¥è¯¢
            print(f"ğŸ” åˆ†ææŸ¥è¯¢: {user_query}")
            self.logger.debug(f"å¼€å§‹åˆ†ææŸ¥è¯¢: {user_query}")

            analyzed_query = self.query_analyzer.analyze_query(user_query)

            intent_result = analyzed_query.intent_result
            print(f"   è¯†åˆ«æ„å›¾: {intent_result.intent.value}")
            print(f"   æ•°æ®æº: {analyzed_query.data_source.table}")
            print(".2f")

            # è®°å½•æ„å›¾è¯†åˆ«ç»“æœ
            self.business_logger.info(
                f"æ„å›¾è¯†åˆ«: '{user_query}' -> {intent_result.intent.value} (ç½®ä¿¡åº¦: {intent_result.confidence:.2f})"
            )

            # 2. æ„å»ºæ‰§è¡Œä»»åŠ¡
            print("ğŸ—ï¸ æ„å»ºæ‰§è¡Œä»»åŠ¡")
            task = self.task_builder.build_task(
                analyzed_query=analyzed_query,
                engine_type=self.engine_type,
                priority=kwargs.get('priority', 1),
                timeout_seconds=kwargs.get('timeout', 3600)
            )

            print(f"   ä»»åŠ¡ID: {task.task_config.task_id}")
            print(f"   SQL: {task.sql_query[:100]}...")

            # è®°å½•SQLç”Ÿæˆ
            self.business_logger.info(f"ç”ŸæˆSQL ({self.engine_type}): {task.sql_query[:100]}...")

            # 3. æ‰§è¡ŒæŸ¥è¯¢
            print("âš¡ æ‰§è¡ŒæŸ¥è¯¢")
            execution_start = time.time()
            execution_result = self.execution_engine.execute_query(task.sql_query, task)
            execution_time = time.time() - execution_start
            print(".2f")

            # è®°å½•æ‰§è¡Œç»“æœ
            if execution_result.get('success'):
                self.business_logger.info(
                    f"ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task.task_config.task_id} | è€—æ—¶: {execution_time:.3f}s | è¿”å›è¡Œæ•°: {execution_result.get('row_count', 0)}"
                )
            else:
                self.business_logger.error(
                    f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.task_config.task_id} | è€—æ—¶: {execution_time:.3f}s | é”™è¯¯: {execution_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                )
            # 4. å¤„ç†ç»“æœ
            print("ğŸ“Š å¤„ç†ç»“æœ")
            processed_result = self.result_processor.process_result(
                execution_result=execution_result,
                analyzed_query=analyzed_query,
                output_format=output_format,
                **kwargs
            )

            # æ·»åŠ é¢å¤–çš„å…ƒä¿¡æ¯
            processed_result['query_info'] = {
                'original_query': user_query,
                'analyzed_query': self.query_analyzer.to_dict(analyzed_query),
                'task_info': task.to_dict(),
                'total_time': execution_time
            }

            if processed_result.get('success'):
                print("âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸ")
            else:
                print(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {processed_result.get('error')}")

            return processed_result

        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"

            print(f"âŒ {error_msg}")

            return {
                'success': False,
                'error': error_msg,
                'timestamp': datetime.now().isoformat(),
                'execution_time': execution_time
            }

    def preview_query(self, user_query: str, sample_size: int = 5) -> Dict[str, Any]:
        """
        é¢„è§ˆæŸ¥è¯¢ç»“æœï¼ˆé‡‡æ ·ï¼‰

        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            sample_size: é‡‡æ ·å¤§å°

        Returns:
            dict: é¢„è§ˆç»“æœ
        """
        if not self.connected:
            return {'success': False, 'error': 'æ‰§è¡Œå¼•æ“æœªè¿æ¥'}

        try:
            # åˆ†ææŸ¥è¯¢
            analyzed_query = self.query_analyzer.analyze_query(user_query)

            # æ„å»ºé‡‡æ ·ä»»åŠ¡
            task = self.task_builder.build_task(analyzed_query, self.engine_type)

            # æ‰§è¡Œé‡‡æ ·æŸ¥è¯¢
            if task.sample_sql:
                execution_result = self.execution_engine.execute_query(task.sample_sql, task)
                processed_result = self.result_processor.process_result(
                    execution_result, analyzed_query, 'table'
                )

                return {
                    'success': True,
                    'preview_data': processed_result.get('data', {}),
                    'sample_size': sample_size,
                    'total_estimated': 'æœªçŸ¥'  # å¯ä»¥é€šè¿‡count_sqlè·å–
                }
            else:
                return {'success': False, 'error': 'æ— æ³•ç”Ÿæˆé‡‡æ ·æŸ¥è¯¢'}

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def get_status(self) -> Dict[str, Any]:
        """è·å–AgentçŠ¶æ€"""
        status = {
            'connected': self.connected,
            'engine_type': self.engine_type,
            'timestamp': datetime.now().isoformat()
        }

        if self.execution_engine:
            status['engine_status'] = self.execution_engine.get_status()
        else:
            status['engine_status'] = {'connected': False}

        return status

    def list_supported_engines(self) -> List[str]:
        """åˆ—å‡ºæ”¯æŒçš„æ‰§è¡Œå¼•æ“"""
        return EngineFactory.get_supported_engines()

    def estimate_query_cost(self, user_query: str) -> Dict[str, Any]:
        """
        ä¼°ç®—æŸ¥è¯¢æˆæœ¬

        Returns:
            dict: æˆæœ¬ä¼°ç®—ä¿¡æ¯
        """
        try:
            analyzed_query = self.query_analyzer.analyze_query(user_query)
            task = self.task_builder.build_task(analyzed_query, self.engine_type)

            estimation = self.task_builder.estimate_execution_time(task)

            # è·å–æ•°æ®é‡ä¼°ç®—
            if self.connected and task.count_sql:
                count_result = self.execution_engine.execute_count_query(task.count_sql, task)
                estimation['estimated_row_count'] = count_result
            else:
                estimation['estimated_row_count'] = 'æœªçŸ¥'

            return {
                'success': True,
                'estimation': estimation,
                'query_complexity': self.task_builder._calculate_complexity(analyzed_query)
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def batch_query(self, queries: List[str], output_format: str = "json") -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ‰§è¡ŒæŸ¥è¯¢

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            output_format: è¾“å‡ºæ ¼å¼

        Returns:
            list: æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        results = []

        for i, query in enumerate(queries, 1):
            print(f"\nğŸ“ æ‰§è¡ŒæŸ¥è¯¢ {i}/{len(queries)}")
            result = self.query(query, output_format)
            result['batch_index'] = i
            results.append(result)

        return results

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.connect()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.disconnect()
