#!/usr/bin/env python3
"""
BigData Agenté›†æˆæµ‹è¯•
"""

import sys
import os
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_nlp_components():
    """æµ‹è¯•NLPç»„ä»¶"""
    print("=== æµ‹è¯•NLPç»„ä»¶ ===")

    try:
        from bigdata_agent.nlp.intent_recognizer import IntentRecognizer
        from bigdata_agent.nlp.query_analyzer import QueryAnalyzer

        # æµ‹è¯•æ„å›¾è¯†åˆ«å™¨
        recognizer = IntentRecognizer()

        test_queries = [
            "ç»Ÿè®¡æ˜¨å¤©ç”¨æˆ·æ³¨å†Œæ•°",
            "åˆ†æå„çœä»½é”€å”®é¢å˜åŒ–è¶‹åŠ¿",
            "ç­›é€‰æ´»è·ƒç”¨æˆ·",
            "æŒ‰åŸå¸‚åˆ†ç»„ç»Ÿè®¡è®¢å•é‡"
        ]

        for query in test_queries:
            result = recognizer.recognize_intent(query)
            print(f"æŸ¥è¯¢: {query}")
            print(f"  æ„å›¾: {result.intent.value} (ç½®ä¿¡åº¦: {result.confidence:.2f})")

        # æµ‹è¯•æŸ¥è¯¢åˆ†æå™¨
        analyzer = QueryAnalyzer()
        analyzed = analyzer.analyze_query("ç»Ÿè®¡æ˜¨å¤©ç”¨æˆ·æ³¨å†Œæ•°")

        print("\næŸ¥è¯¢åˆ†æç»“æœ:")
        print(f"  åŸå§‹æŸ¥è¯¢: {analyzed.original_query}")
        print(f"  æ„å›¾: {analyzed.intent_result.intent.value}")
        print(f"  æ•°æ®æº: {analyzed.data_source.table}")
        print(f"  ç½®ä¿¡åº¦: {analyzed.confidence_score:.2f}")

        return True

    except Exception as e:
        print(f"âŒ NLPç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_task_builder():
    """æµ‹è¯•ä»»åŠ¡æ„å»ºå™¨"""
    print("\n=== æµ‹è¯•ä»»åŠ¡æ„å»ºå™¨ ===")

    try:
        from bigdata_agent.nlp.query_analyzer import QueryAnalyzer
        from bigdata_agent.task.task_builder import TaskBuilder

        analyzer = QueryAnalyzer()
        builder = TaskBuilder()

        analyzed_query = analyzer.analyze_query("ç»Ÿè®¡å„çœä»½ç”¨æˆ·æ•°")
        task = builder.build_task(analyzed_query, engine_type="spark")

        print("ä»»åŠ¡æ„å»ºç»“æœ:")
        print(f"  ä»»åŠ¡ID: {task.task_config.task_id}")
        print(f"  ä»»åŠ¡ç±»å‹: {task.task_config.task_type}")
        print(f"  SQL: {task.sql_query[:100]}...")

        # ä¼°ç®—æ‰§è¡Œæ—¶é—´
        estimation = builder.estimate_execution_time(task)
        print(f"  é¢„ä¼°æ—¶é—´: {estimation['estimated_minutes']:.1f}åˆ†é’Ÿ")

        return True

    except Exception as e:
        print(f"âŒ ä»»åŠ¡æ„å»ºå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_result_processor():
    """æµ‹è¯•ç»“æœå¤„ç†å™¨"""
    print("\n=== æµ‹è¯•ç»“æœå¤„ç†å™¨ ===")

    try:
        from bigdata_agent.result.result_processor import ResultProcessor
        from bigdata_agent.nlp.query_analyzer import QueryAnalyzer

        processor = ResultProcessor()
        analyzer = QueryAnalyzer()

        # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ
        mock_result = {
            'success': True,
            'data': [
                {'province': 'åŒ—äº¬', 'count': 1000},
                {'province': 'ä¸Šæµ·', 'count': 800},
                {'province': 'å¹¿å·', 'count': 600}
            ],
            'columns': ['province', 'count'],
            'row_count': 3,
            'execution_time': 2.5,
            'task_id': 'test-task-001'
        }

        analyzed_query = analyzer.analyze_query("ç»Ÿè®¡å„çœä»½ç”¨æˆ·æ•°")

        # æµ‹è¯•ä¸åŒæ ¼å¼çš„è¾“å‡º
        for fmt in ['json', 'table']:
            processed = processor.process_result(mock_result, analyzed_query, fmt)
            print(f"  {fmt.upper()}æ ¼å¼å¤„ç†æˆåŠŸ: {processed['success']}")

        return True

    except Exception as e:
        print(f"âŒ ç»“æœå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_agent_initialization():
    """æµ‹è¯•Agentåˆå§‹åŒ–"""
    print("\n=== æµ‹è¯•Agentåˆå§‹åŒ– ===")

    try:
        from bigdata_agent import BigDataAgent

        # æµ‹è¯•Agentåˆ›å»º
        agent = BigDataAgent(engine_type="spark")
        print("âœ… Agentåˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•çŠ¶æ€æŸ¥è¯¢
        status = agent.get_status()
        print(f"âœ… çŠ¶æ€æŸ¥è¯¢æˆåŠŸ: è¿æ¥çŠ¶æ€ {status['connected']}")

        # æµ‹è¯•æ”¯æŒçš„å¼•æ“
        engines = agent.list_supported_engines()
        print(f"âœ… æ”¯æŒçš„å¼•æ“: {engines}")

        return True

    except Exception as e:
        print(f"âŒ Agentåˆå§‹åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_query_analysis():
    """æµ‹è¯•æŸ¥è¯¢åˆ†æåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æŸ¥è¯¢åˆ†æåŠŸèƒ½ ===")

    try:
        from bigdata_agent.nlp.query_analyzer import QueryAnalyzer

        analyzer = QueryAnalyzer()

        test_cases = [
            "ç»Ÿè®¡æ˜¨å¤©çš„ç”¨æˆ·æ³¨å†Œæ•°",
            "åˆ†æå„åŸå¸‚çš„é”€å”®é¢å˜åŒ–",
            "æŸ¥æ‰¾æ´»è·ƒç”¨æˆ·åˆ—è¡¨",
            "æŒ‰æœˆä»½ç»Ÿè®¡è®¢å•è¶‹åŠ¿",
            "ç­›é€‰é«˜ä»·å€¼å®¢æˆ·"
        ]

        for query in test_cases:
            analyzed = analyzer.analyze_query(query)
            print(f"\næŸ¥è¯¢: {query}")
            print(f"  æ„å›¾: {analyzed.intent_result.intent.value}")
            print(f"  ç½®ä¿¡åº¦: {analyzed.confidence_score:.2f}")
            print(f"  æ•°æ®æº: {analyzed.data_source.table}")

        return True

    except Exception as e:
        print(f"âŒ æŸ¥è¯¢åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False

def test_config_loading():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("\n=== æµ‹è¯•é…ç½®åŠ è½½ ===")

    try:
        from bigdata_agent.llms.settings_loader import load_settings_from_json

        # å°è¯•åŠ è½½é…ç½®ï¼ˆå¦‚æœsetting.jsonå­˜åœ¨ï¼‰
        try:
            settings = load_settings_from_json()
            print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            print(f"  é…ç½®é¡¹æ•°é‡: {len(settings)}")
        except FileNotFoundError:
            print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        except Exception as e:
            print(f"âš ï¸ é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")

        return True

    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹BigData Agentæµ‹è¯•å¥—ä»¶\n")

    tests = [
        ("é…ç½®åŠ è½½", test_config_loading),
        ("NLPç»„ä»¶", test_nlp_components),
        ("ä»»åŠ¡æ„å»ºå™¨", test_task_builder),
        ("ç»“æœå¤„ç†å™¨", test_result_processor),
        ("Agentåˆå§‹åŒ–", test_agent_initialization),
        ("æŸ¥è¯¢åˆ†æ", test_query_analysis)
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name} - é€šè¿‡")
            else:
                print(f"âŒ {test_name} - å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} - å¼‚å¸¸: {e}")

    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼BigData Agentå‡†å¤‡å°±ç»ªï¼")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶")
        return False

def main():
    """ä¸»å‡½æ•°"""
    success = run_all_tests()

    # å¦‚æœæœ‰é…ç½®æ–‡ä»¶ï¼Œæµ‹è¯•å®Œæ•´åŠŸèƒ½
    if Path("setting.json").exists():
        print("\nğŸ”§ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶ï¼Œæµ‹è¯•å®Œæ•´AgentåŠŸèƒ½...")

        try:
            from bigdata_agent import BigDataAgent

            agent = BigDataAgent()
            if agent.connect():
                print("âœ… Agentè¿æ¥æˆåŠŸ")

                # æµ‹è¯•ç®€å•æŸ¥è¯¢
                result = agent.estimate_query_cost("ç»Ÿè®¡ç”¨æˆ·æ•°æ®")
                if result['success']:
                    print("âœ… æˆæœ¬ä¼°ç®—åŠŸèƒ½æ­£å¸¸")
                else:
                    print(f"âš ï¸ æˆæœ¬ä¼°ç®—åŠŸèƒ½å¼‚å¸¸: {result.get('error')}")

                agent.disconnect()
            else:
                print("âš ï¸ Agentè¿æ¥å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç¼ºå°‘ä¾èµ–æˆ–é…ç½®ï¼‰")

        except Exception as e:
            print(f"âš ï¸ å®Œæ•´åŠŸèƒ½æµ‹è¯•å¼‚å¸¸: {e}")

    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())
